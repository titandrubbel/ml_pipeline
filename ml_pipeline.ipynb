{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineRun, StepRun, PortDataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.core.authentication import AzureCliAuthentication\n",
    "from azureml.pipeline.core import PipelineParameter\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "#Check azure ML SDK version\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from configuration JSON file with subscription, resource, and workspace name data.\n",
    "cli_auth = AzureCliAuthentication()\n",
    "\n",
    "ws = Workspace.from_config(path=\"./\")\n",
    "\n",
    "# print workspace created\n",
    "print(ws.name, ws.location, ws.resource_group, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test_auto_deploy\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "print(exp.name, exp.workspace.name, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get default datastore (blob storage)\n",
    "pipeline_datastore = Datastore(ws, \"datastore_pipeline\")\n",
    "pipeline_datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach computing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# For using GPU VM, set SKU to STANDARD_NC6\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\n",
    "\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"creating new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=provisioning_config)\n",
    "\n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_run_config = RunConfiguration()\n",
    "\n",
    "aml_run_config.target = compute_name\n",
    "aml_run_config.environment.docker.enabled = True\n",
    "aml_run_config.environment.docker.base_image = \"mcr.microsoft.com/azureml/base:latest\" \n",
    "aml_run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "# Dependecies for the model train step\n",
    "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=['pandas', 'scikit-learn', 'numpy', 'nltk'],\n",
    "    pip_packages=['joblib', 'imblearn', 'sklearn','azureml-sdk','pyyaml','GitPython','ansiblemetrics','pydriller','requests','datetime','iacminer', 'pygithub', 'azure-cli-core'],\n",
    "    pin_sdk_version=False)\n",
    "\n",
    "print(aml_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For first run upload JSON file with repo url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload repo metrics (results from repo minor)\n",
    "#pipeline_datastore.upload_files([\"./data/repo_url.json\"], target_path=\"input_data\", overwrite=True)\n",
    "\n",
    "#Datsets objects used for reading data from workspace\n",
    "#repo_url = Dataset.File.from_files(pipeline_datastore.path( './input_data/repo_url.json'))\n",
    "\n",
    "#Register list to workspace\n",
    "#repo_url = repo_url.register(workspace = ws, name = \"repo_url\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline data, data references and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference the data uploaded to blob storage using DataReference\n",
    "input_data = DataReference(\n",
    "    datastore=pipeline_datastore,\n",
    "    data_reference_name=\"repo_url\",\n",
    "    path_on_datastore=\"input_data/repo_url.json\")\n",
    "\n",
    "#Pipeline data for transferring intermediate data\n",
    "github_data = PipelineData(\"github_data\",datastore=pipeline_datastore)\n",
    "repo_metrics = PipelineData(\"metrics_data\",datastore=pipeline_datastore)\n",
    "metrics_clean = PipelineData(\"metrics_clean\",datastore=pipeline_datastore)\n",
    "model_file = PipelineData(\"train_model\",datastore=pipeline_datastore)\n",
    "final_model = PipelineData(\"final_model\",datastore=pipeline_datastore)\n",
    "container_store = PipelineData(\"container_store\",datastore=pipeline_datastore)\n",
    "\n",
    "#Pipeline parameters for transferring repo name and repo owner\n",
    "repo_name_par = PipelineParameter(name=\"repo_name\", default_value='molecule')\n",
    "repo_owner_par = PipelineParameter(name=\"repo_owner\", default_value='ansible-community')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create each pipeline step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/github_cloner\"\n",
    "\n",
    "github_cloner = PythonScriptStep(name=\"github_cloner\",\n",
    "                        script_name=\"./github_cloner.py\",\n",
    "                        arguments=[\"--github_list\", input_data,\"--repo_owner\",repo_owner_par,\n",
    "                                   \"--repo_name\",repo_name_par,\"--raw_data\",github_data],\n",
    "                        inputs=[input_data],\n",
    "                        outputs=[github_data],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Github cloner step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/repo_miner\"\n",
    "repo_miner = PythonScriptStep(name=\"repo_miner\",\n",
    "                        script_name=\"./repo_miner.py\",\n",
    "                        arguments=[\"--repo_owner\",repo_owner_par,\"--repo_name\",repo_name_par,\"--raw_data\",github_data,\"--metrics_data\",repo_metrics],\n",
    "                        inputs=[github_data],\n",
    "                        outputs=[repo_metrics],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Repo miner step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/cleaning\"\n",
    "metrics_cleaning = PythonScriptStep(name=\"metrics_cleaning\",\n",
    "                        script_name=\"./cleaning.py\",\n",
    "                        arguments=[\"--repo_owner\",repo_owner_par,\"--repo_name\",repo_name_par,\"--metrics_data\",repo_metrics,\"--metrics_clean\",metrics_clean],\n",
    "                        inputs=[repo_metrics],\n",
    "                        outputs=[metrics_clean],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Metrics cleaning step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/training\"\n",
    "train_model = PythonScriptStep(name=\"model_training\",\n",
    "                        script_name=\"./train.py\",\n",
    "                        arguments=[\"--repo_owner\",repo_owner_par,\"--repo_name\",repo_name_par,\"--metrics_clean\",metrics_clean,\"--train_model\",model_file],\n",
    "                        inputs=[metrics_clean],\n",
    "                        outputs=[model_file],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Model training step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/evaluate\"\n",
    "evaluate_model = PythonScriptStep(name=\"model_evaluation\",\n",
    "                        script_name=\"./evaluate.py\",\n",
    "                        arguments=[\"--repo_owner\",repo_owner_par,\"--repo_name\",repo_name_par,\"--train_model\",model_file,\"--final_model\",final_model],\n",
    "                        inputs=[model_file],\n",
    "                        outputs=[final_model],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Model evaluation step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the steps run after each other\n",
    "#aci_webservice.run_after(container_image)\n",
    "container_image.run_after(evaluate_model)\n",
    "evaluate_model.run_after(train_model)\n",
    "train_model.run_after(metrics_cleaning)\n",
    "metrics_cleaning.run_after(repo_miner)\n",
    "repo_miner.run_after(github_cloner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [github_cloner, repo_miner, metrics_cleaning, train_model, evaluate_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit pipeline and see resuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline, attach to workspace and associate steps\n",
    "pipeline1 = Pipeline(workspace=ws, steps=steps) \n",
    "\n",
    "pipeline1.validate()\n",
    "\n",
    "pipeline_run1= exp.submit(pipeline1, regenerate_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(pipeline_run1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info of pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in pipeline_run1.get_steps():\n",
    "    print(\"Outputs of step \" + step.name)\n",
    "    \n",
    "    output_dict = step.get_outputs()\n",
    "\n",
    "    for name, output in output_dict.items():\n",
    "        \n",
    "        output_reference = output.get_port_data_reference() # Get output port data reference\n",
    "        print(\"\\tname: \" + name)\n",
    "        print(\"\\tdatastore: \" + output_reference.datastore_name)\n",
    "        print(\"\\tpath on datastore: \" + output_reference.path_on_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish a pipeline from the submitted pipeline run\n",
    "pipeline_name = \"deployment\"\n",
    "description = \"Defect prediction pippeline: from github cloning to model evaluation and implementation\"\n",
    "published_pipeline = pipeline_run1.publish_pipeline(name=pipeline_name, description=description, version=\"1\", continue_on_step_failure=True)\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the endpoint URL\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(\"You can perform HTTP POST on URL {} to trigger this pipeline\".format(rest_endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All submitted pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "all_pub_pipelines = PublishedPipeline.list(ws)\n",
    "all_pub_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most recent model\n",
    "model_list = Model.list(ws)\n",
    "production_model = next(\n",
    "    filter(\n",
    "        lambda x: x.created_time == max(model.created_time for model in model_list),\n",
    "        model_list,\n",
    "    )\n",
    ")\n",
    "\n",
    "model = Model(ws, name=production_model.name)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get ADD token\n",
    "auth = InteractiveLoginAuthentication()\n",
    "aad_token = auth.get_authentication_header()\n",
    "#experiment_name = \"Defect_prediction_pipeline\"\n",
    "\n",
    "# specify the param when running the pipeline\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=aad_token, \n",
    "                         json={\"ExperimentName\": experiment_name },\n",
    "                        \"ParameterAssignments\": {\n",
    "                            \"repo_name\": 'ansible-community',\n",
    "                            \"repo_owner\": 'molecule'},\n",
    "                        \"RunSource\": \"SDK\")\n",
    "\n",
    "run_id = response.json()\n",
    "run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with ACI webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_store = PipelineData(\"ACI_store\",datastore=pipeline_datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the steps run after each other\n",
    "aci_webservice.run_after(evaluate_model)\n",
    "evaluate_model.run_after(train_model)\n",
    "train_model.run_after(metrics_cleaning)\n",
    "metrics_cleaning.run_after(repo_miner)\n",
    "repo_miner.run_after(github_cloner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_directory = \"./scripts/deployment\"\n",
    "aci_webservice = PythonScriptStep(name=\"container_image\",\n",
    "                        script_name=\"./aci_webservice_new.py\",\n",
    "                        arguments=[\"--repo_owner\",repo_owner_par,\"--repo_name\",repo_name_par,\"--final_model\",final_model, \"--aci_store\",aci_store],\n",
    "                        inputs=[final_model],\n",
    "                        outputs = [aci_store],\n",
    "                        compute_target=compute_name,\n",
    "                        runconfig=aml_run_config,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "\n",
    "print(\"Container image step created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [github_cloner, repo_miner, metrics_cleaning, train_model, evaluate_model, aci_webservice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline, attach to workspace and associate steps\n",
    "pipeline1 = Pipeline(workspace=ws, steps=steps) \n",
    "\n",
    "pipeline1.validate()\n",
    "\n",
    "pipeline_run1= exp.submit(pipeline1, regenerate_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(pipeline_run1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run1.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the web service, passing the input data\n",
    "response = service.run(input_data = \"test\")\n",
    "\n",
    "# Get the predictions\n",
    "predictions = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
